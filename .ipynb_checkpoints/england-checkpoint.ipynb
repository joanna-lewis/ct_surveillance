{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Chlamydia in England, 2012\n",
    "\n",
    "This example illustrates a method for using chlamydia surveillance data to estimate prevalence. Surveillance data on chlamydia testing and diagnosis rates in England in 2012 were downloaded from: http://www.chlamydiascreening.nhs.uk/ps/data.asp (downloaded 17 April 2015).\n",
    "\n",
    "\n",
    "|           | Men         |             |       |Women       |             |        |\n",
    "|-----------|-------------|-------------|-------|------------|-------------|--------|\n",
    "|           | 15-19 years | 20-24 years | Total |15-19 years | 20-24 years | Total  |\n",
    "|Population |1685620      | 1833395     |3519015|1600686     |1788156      |3388842 |\n",
    "|Tests      |232668       | 334240      |566908 |520358      |685538       |1205896 |\n",
    "|Diagnoses  |15213        | 33174       |48387  |42874       |45227        |88101   |\n",
    "\n",
    "Data on sexual behaviour from Natsal-3 are available from the UK data service: https://www.ukdataservice.ac.uk/ (downloaded 23 September 2015). These were used to infer 95% confidence intervals for the proportions of men and women, aged 16-19 and 20-24, who were sexually active (see the accompanying R script; note that no 15-year-olds were recruited to Natsal-3). These 95% confidence intervals were in turn used to derive beta-distribution priors for the proportion sexually active within each sex and age group.\n",
    "\n",
    "## Sampling for testing and diagnosis rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from scipy.stats import beta\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "######################\n",
    "# parameters of beta distributions representing the proportion of the population sexually \n",
    "# active, by sex and age group\n",
    "######################\n",
    "\n",
    "# men, 16-19\n",
    "[alpha_m_16_19, beta_m_16_19] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.6747424, 0.741327698),\n",
    "    [1,1]\n",
    "    )\n",
    "# men, 20-24\n",
    "[alpha_m_20_24, beta_m_20_24] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.8844970, 0.933759842),\n",
    "    [1,1]\n",
    "    )\n",
    "# men, 16-24\n",
    "[alpha_m_16_24, beta_m_16_24] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.8023836019, 0.843403825),\n",
    "    [1,1]\n",
    "    )\n",
    "# women, 16-19\n",
    "[alpha_f_16_19, beta_f_16_19] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.6583593, 0.723554878),\n",
    "    [1,1]\n",
    "    )\n",
    "# women, 20-24\n",
    "[alpha_f_20_24, beta_f_20_24] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.8904135, 0.934417684),\n",
    "    [1,1]\n",
    "    )\n",
    "# women, 16-24\n",
    "[alpha_f_16_24, beta_f_16_24] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.7998634469, 0.837979601),\n",
    "    [1,1]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, sample from distributions for the probability of being sexually active, the size of the sexually active population and the testing and diagnosis rates per person per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed = 12345\n",
    "\n",
    "from scipy.stats import gamma\n",
    "from numpy.random import normal\n",
    "\n",
    "n_sample = 10000\n",
    "\n",
    "# sexually-active populations:\n",
    "p_active_m_16_19 = random.beta(alpha_m_16_19, beta_m_16_19, size=n_sample) # 16-19 yo only\n",
    "pop_active_m_15_19 = random.binomial(1685620, p_active_m_16_19, size=n_sample)\n",
    "\n",
    "p_active_m_20_24 = random.beta(alpha_m_20_24, beta_m_20_24, size=n_sample) # 20-24 yo only\n",
    "pop_active_m_20_24 = random.binomial(1833395, p_active_m_20_24, size=n_sample)\n",
    "\n",
    "p_active_m_16_24 = random.beta(alpha_m_16_24, beta_m_16_24, size=n_sample) # 16-24 yo only\n",
    "pop_active_m_15_24 = random.binomial(3519015, p_active_m_16_24, size=n_sample)\n",
    "\n",
    "p_active_f_16_19 = random.beta(alpha_f_16_19, beta_f_16_19, size=n_sample) # 16-19 yo only\n",
    "pop_active_f_15_19 = random.binomial(1600686, p_active_f_16_19, size=n_sample)\n",
    "\n",
    "p_active_f_20_24 = random.beta(alpha_f_20_24, beta_f_20_24, size=n_sample) # 20-24 yo only\n",
    "pop_active_f_20_24 = random.binomial(1788156, p_active_f_20_24, size=n_sample)\n",
    "\n",
    "p_active_f_16_24 = random.beta(alpha_f_16_24, beta_f_16_24, size=n_sample) # 16-24 yo only\n",
    "pop_active_f_15_24 = random.binomial(3388842, p_active_f_16_24, size=n_sample)\n",
    "\n",
    "# testing and diagnosis rates, per person per year\n",
    "test_rate_m_15_19 = random.gamma(232668, 1, size=n_sample)/pop_active_m_15_19\n",
    "test_rate_m_20_24 = random.gamma(334240, 1, size=n_sample)/pop_active_m_20_24\n",
    "test_rate_m_15_24 = random.gamma(566908, 1, size=n_sample)/pop_active_m_15_24\n",
    "\n",
    "diag_rate_m_15_19 = random.gamma(15213, 1, size=n_sample)/pop_active_m_15_19\n",
    "diag_rate_m_20_24 = random.gamma(33174, 1, size=n_sample)/pop_active_m_20_24\n",
    "diag_rate_m_15_24 = random.gamma(48387, 1, size=n_sample)/pop_active_m_15_24\n",
    "\n",
    "diag_rate_f_15_19 = random.gamma(42874, 1, size=n_sample)/pop_active_f_15_19\n",
    "diag_rate_f_20_24 = random.gamma(45227, 1, size=n_sample)/pop_active_f_20_24\n",
    "diag_rate_f_15_24 = random.gamma(88101, 1, size=n_sample)/pop_active_f_15_24\n",
    "\n",
    "test_rate_f_15_19 = random.gamma(520358, 1, size=n_sample)/pop_active_f_15_19\n",
    "test_rate_f_20_24 = random.gamma(685538, 1, size=n_sample)/pop_active_f_20_24\n",
    "test_rate_f_15_24 = random.gamma(1205896, 1, size=n_sample)/pop_active_f_15_24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling natural history, behavioural and other parameters\n",
    "\n",
    "Priors for the proportion of incident infections which are asymptomatic and the test performance were taken directly from published studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proportion of incident infections asymptomatic is not known, so we use estimates of the \n",
    "# proportion of _prevalent_ infections asymptomatic. Note that these provide an upper bound\n",
    "# because treatment seeking in symptomatic cases will deplete the symptomatic pool.\n",
    "p_asymp_m = random.beta(69 + 1, 78 - 69 + 1, size=n_sample) # McKay et al. Lancet (2003) 88% \n",
    "p_asymp_f = random.beta(135 + 1, 26 + 1, size=n_sample) # Kahn et al. Sex Transm Dis (2003) 84% NB numbers taken from text, p656\n",
    "\n",
    "# test performance\n",
    "p_true_pos_m = random.beta(32+1, 0+1, size=n_sample) # Horner J. Clin. Microbiol (2005): 32 of 32 infected samples tested +ve\n",
    "p_false_pos_m = random.beta(2+1, 950+1, size=n_sample) # Horner J. Clin. Microbiol (2005): 2 of 952 uninfected samples tested +ve\n",
    "p_true_pos_f = random.beta(129+1, 12+1, size=n_sample) # Low Health Technol Assess (2007): 129 of 141 infected samples tested +ve\n",
    "p_false_pos_f = random.beta(4+1, 2323+1, size=n_sample) # Low Health Technol Assess (2007): 4 of 2327 uninfected samples tested +ve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of treatment seeking by symptomatic cases\n",
    "We use a Metropolis-Hastings algorithm to sample for the rate of treatment following onset of symptoms, assuming a constant hazard of treatment beginning with the onset of symptoms. Data consist of the estimated proportion of GUM clinic patients with symptoms whose symptoms had started less than one, 1-2, 2-4, 4-6 and more than 6 weeks previously (Mercer _et al._, _Sex. Transm. Infect._ **83**:400-405; 2007).\n",
    "\n",
    "|           | Proportion  |                         |\n",
    "|-----------|-------------|-------------------------|\n",
    "|           | Estimate    | 95% Confidence Interval |\n",
    "|< 1 week   |26.7%        | (14.4, 44.2)%           |\n",
    "|7-13 days  |14.4%        | (6.1, 30.2)%            |\n",
    "|14-27 days |20.8%        | (13.3, 31.0)%           |\n",
    "|4-6 weeks  |16.6%        | (8.5, 29.9)%            |\n",
    "|>6 weeks   |21.5%        | (5.5, 56.4)%            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for calculating likelihood of multinomial data\n",
    "%run multinomial_pmf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find beta distributions corresponding to 95% CIs reported in Mercer Sex. Transm. Infect. (2007) (see table above).\n",
    "\n",
    "from numpy import *\n",
    "from scipy.stats import beta\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "a = empty(5)\n",
    "b = empty(5)\n",
    "\n",
    "# < 1 week\n",
    "[a[0], b[0]] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.144, 0.442),\n",
    "    [1,1]\n",
    "    )\n",
    "\n",
    "# 7-13 days\n",
    "[a[1], b[1]] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.061, 0.302),\n",
    "    [1,1]\n",
    "    )\n",
    "\n",
    "# 14-27 days\n",
    "[a[2], b[2]] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.133, 0.310),\n",
    "    [1,1]\n",
    "    )\n",
    "\n",
    "# 28-41 days\n",
    "[a[3], b[3]] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.085, 0.299),\n",
    "    [1,1]\n",
    "    )\n",
    "\n",
    "# 42 days and over\n",
    "[a[4], b[4]] = fsolve(\n",
    "    lambda x: array(beta.interval(0.95, x[0], x[1], loc=0, scale=1))\n",
    "    - (0.055, 0.564),\n",
    "    [1,1]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224\n",
      "14.3134818998\n"
     ]
    }
   ],
   "source": [
    "# Metropolis-Hastings to get a sample for rate of treatment\n",
    "\n",
    "i = 0\n",
    "att_symp = empty(n_sample+1000) # testing rate per person per year. Allow 1000 extra samples for burn-in\n",
    "ll = empty(n_sample+1000) # log-likelihood\n",
    "props = empty([n_sample+1000, 5]) # simulated data, for posterior predictive check\n",
    "old = 0.04 # starting sample value\n",
    "new = 0.04 # starting sample value\n",
    "\n",
    "# simulate probabilities corresponding to data\n",
    "\n",
    "# proportion expected in each time window\n",
    "tps = array([0., 7., 14., 28., 42., Inf])\n",
    "simp_new = exp(-new*tps[:5]) - exp(-new*tps[1:])\n",
    "\n",
    "acc=0.\n",
    "while i < n_sample+1000: # to do samples for p_test_symp\n",
    "    \n",
    "    new = random.normal(old, 0.05) # generate a sample from normal distribution\n",
    "    \n",
    "    if new < 0:\n",
    "        att_symp[i] = old # reject\n",
    "        ll[i] = -1e10\n",
    "    else:\n",
    "        simp_old = exp(-old*tps[:5]) - exp(-old*tps[1:])\n",
    "        simp_new = exp(-new*tps[:5]) - exp(-new*tps[1:])\n",
    "\n",
    "        if sum(simp_new > 0) != len(tps) - 1:\n",
    "            att_symp[i] = old # reject\n",
    "            ll[i] = -1e10\n",
    "        else:\n",
    "            # simulate probabilities corresponding to the data\n",
    "            log_ratio = sum(beta.logpdf(simp_new, a, b, loc=0, scale=1)) - sum(beta.logpdf(simp_old, a, b, loc=0, scale=1))\n",
    "    \n",
    "            if log(random.uniform(0,1)) <  log_ratio:\n",
    "                att_symp[i] = new # accept\n",
    "                ll[i] = sum(beta.logpdf(simp_new, a, b, loc=0, scale=1))\n",
    "                old = new\n",
    "                acc = acc+1\n",
    "            else:\n",
    "                att_symp[i] = old # reject\n",
    "                ll[i] = sum(beta.logpdf(simp_old, a, b, loc=0, scale=1))\n",
    "    \n",
    "    props[i] = simp_old\n",
    "    i = i+1\n",
    "    \n",
    "att_symp = att_symp[1000:] # remove burn-in samples\n",
    "ll = ll[1000:] # log-likelihood\n",
    "    \n",
    "print acc/(n_sample+1000) # print the proportion of samples accepted\n",
    "print mean(att_symp)*365.25\n",
    "print 365.25*percentile(att_symp, [2.5, 97.5])\n",
    "\n",
    "att_symp = att_symp*365.25 # convert rate from day^-1 to year^-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# diagnostics and posterior predictive checks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import multinomial\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.plot(att_symp, alpha=0.5)\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "    \n",
    "ax2.plot(range(43),median(att_symp/365.25)*exp(-median(att_symp/365.25)*array(range(43))),'b')\n",
    "#plt.plot(range(50),percentile(att_symp, 2.5)*exp(-percentile(att_symp, 2.5)*array(range(50))),'b--')\n",
    "#plt.plot(range(50),percentile(att_symp, 97.5)*exp(-percentile(att_symp, 97.5)*array(range(50))),'b--')\n",
    "\n",
    "#ax2.set_ylim([0,0.1])\n",
    "ax2.set_xlim([0,50])\n",
    "ax2.errorbar([3.5,10.5,21,35, 46],\n",
    "            [0.267/7, 0.144/7, 0.208/14, 0.166/14, 0.215/10],\n",
    "            abs(array([[0.144/7, 0.061/7, 0.133/14, 0.085/14, 0.055/10],\n",
    "                       [0.442/7, 0.302/7, 0.310/14, 0.299/14, 0.564/10]]\n",
    "                      ) - array([0.267/7, 0.144/7, 0.208/14, 0.166/14, 0.215/10])\n",
    "    ), color = 'r', fmt='.')\n",
    "\n",
    "ax2.plot([0,7,7,14,14,28,28,42], repeat(percentile(props[:,:4],50,0)/array([7,7,14,14]),2), 'b--')\n",
    "ax2.plot([42,50], repeat(percentile(props[:,4],50,0)/array([10]),2), 'b--')\n",
    "ax2.fill_between(\n",
    "    [0,7,7,14,14,28,28,42,42,50], \n",
    "    repeat(percentile(props,2.5,0)/array([7,7,14,14,10]),2), \n",
    "    repeat(percentile(props,97.5,0)/array([7,7,14,14,10]),2),\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Rate of seeking treatment (year^-1)')\n",
    "ax2.set_xlabel('Days since onset of symptoms')\n",
    "ax2.set_ylabel('Proportion of patients surveyed')\n",
    "\n",
    "ax2.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MCMC chain is illustrated in the left-hand panel, and seem to have converged well. \n",
    "\n",
    "The right-hand panel shows the probability density of the time between onset of symptoms and attending the GUM clinic where patients were surveyed, to 42 days (solid blue line). The blue shaded area and dashed line show the central 95% and median of simulated histograms for waiting times to clinic, with bins corresponding to time windows reported in the data. The last bin contains all times longer than six weeks and has been divided by 10 (as opposed to the width of the window) to make it readable. For comparison, red error bars show the reported proportions of patients with treatment-seeking times within each time window (estimate and 95% CI), normalised to be on the same scale as the predictions (blue). The good predictive properties of the model are indicated by the agreement between the data, in red, and the posterior predictions in blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of spontaneous clearance of infection\n",
    "\n",
    "Use a similar model for spontaneous clearance of infection, with data from Joyner et al. _Sex Transm. Dis._ (2002)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# Metropolis-Hastings to get a sample for rate of spontaneous clearance in men\n",
    "# assuming a constant hazard of recovery\n",
    "\n",
    "i = 0\n",
    "sc_m = empty(n_sample+1000) # testing rate per person per year\n",
    "ll_m = empty(n_sample+1000) # log-likelihood\n",
    "old = 0.1 # starting sample value\n",
    "\n",
    "acc=0.\n",
    "while i < n_sample+1000: # to do samples for p_test_symp\n",
    "    \n",
    "    new = random.normal(old, 5) # generate a sample from normal distribution\n",
    "    \n",
    "    if new < 0:\n",
    "        sc_m[i] = old # reject\n",
    "        ll_m[i] = -1e10\n",
    "    else:\n",
    "        simp_old = 1 - exp(-array([5, 11.5, 18.5, 32.5, 78])*old/365.25)\n",
    "        simp_new = 1 - exp(-array([5, 11.5, 18.5, 32.5, 78])*new/365.25)\n",
    "                \n",
    "        if sum(simp_new >0) != 5:\n",
    "            sc_m[i] = old # reject\n",
    "            ll_m[i] = -1e10\n",
    "        else:\n",
    "            # simulate probabilities \n",
    "            log_ratio = sum(binom.logpmf([3,2,1,0,1], [15,9,4,4,4], simp_new)) - sum(binom.logpmf([3,2,1,0,1], [15,9,4,4,4], simp_old))            \n",
    "            \n",
    "            if log(random.uniform(0,1)) <  log_ratio: \n",
    "                sc_m[i] = new # accept\n",
    "                ll_m[i] = sum(binom.logpmf([3,2,1,0,1], [15,9,4,4,4], simp_new))\n",
    "                old = new\n",
    "                acc = acc+1\n",
    "            else:\n",
    "                sc_m[i] = old # reject\n",
    "                ll_m[i] = sum(binom.logpmf([3,2,1,0,1], [15,9,4,4,4], simp_old))\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "sc_m = sc_m[1000:] # remove burn-in samples\n",
    "ll_m = ll_m[1000:] # log-likelihood\n",
    "    \n",
    "print acc/(n_sample+1000) # print the proportion of samples accepted\n",
    "print mean(sc_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Metropolis-Hastings to get a sample for rate of spontaneous clearance in women\n",
    "# assuming a constant hazard of recovery\n",
    "\n",
    "i = 0\n",
    "sc_f = empty(n_sample+1000) # testing rate per person per year\n",
    "ll_f = empty(n_sample+1000) # log-likelihood\n",
    "old = 0.1 # starting sample value\n",
    "\n",
    "acc=0.\n",
    "while i < n_sample+1000: # to do samples for p_test_symp\n",
    "    \n",
    "    new = random.normal(old, 5) # generate a sample from normal distribution\n",
    "    \n",
    "    if new < 0:\n",
    "        sc_f[i] = old # reject\n",
    "        ll_f[i] = -1e10\n",
    "    else:\n",
    "        simp_old = 1 - exp(-array([5, 11.5, 18.5, 32.5, 137.5])*old/365.25)\n",
    "        simp_new = 1 - exp(-array([5, 11.5, 18.5, 32.5, 137.5])*new/365.25)\n",
    "                \n",
    "        if sum(simp_new >0) != 5:\n",
    "            sc_f[i] = old # reject\n",
    "            ll_f[i] = -1e10\n",
    "        else:\n",
    "            # simulate probabilities \n",
    "            log_ratio = sum(binom.logpmf([2,7,1,0,3], [12,28,4,8,6], simp_new)) - sum(binom.logpmf([2,7,1,0,3], [12,28,4,8,6], simp_old))\n",
    "            \n",
    "            if log(random.uniform(0,1)) <  log_ratio: \n",
    "                sc_f[i] = new # accept\n",
    "                ll_f[i] = sum(binom.logpmf([3,2,1,0,1], [15,9,4,4,4], simp_new))\n",
    "                old = new\n",
    "                acc = acc+1\n",
    "            else:\n",
    "                sc_f[i] = old # reject\n",
    "                ll_f[i] = sum(binom.logpmf([3,2,1,0,1], [15,9,4,4,4], simp_old))\n",
    "        \n",
    "    i = i+1\n",
    "    \n",
    "sc_f = sc_f[1000:] # remove burn-in samples\n",
    "    \n",
    "print acc/(n_sample+1000) # print the proportion of samples accepted\n",
    "print mean(sc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.plot(sc_m, alpha=0.5)\n",
    "ax1.plot(sc_f, 'r', alpha=0.5)\n",
    "ax1.set_ylim([0,14])\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "\n",
    "# men\n",
    "simdat = zeros([n_sample, 5])\n",
    "for i in xrange(n_sample):\n",
    "    simp = 1 - exp(-array([5, 11.5, 18.5, 32.5, 78])*sc_m[i]/365.25)\n",
    "    simdat[i] = binom.rvs([15,9,4,4,4], simp)\n",
    "    \n",
    "men = ax2.plot(\n",
    "    [5, 11.5, 18.5, 32.5, 78],\n",
    "    array([3,2,1,0,1])/array([15.,9.,4.,4.,4.]), \n",
    "    '.', label='men')\n",
    "mlm = argmax(ll_m)\n",
    "\n",
    "ax2.errorbar([5, 11.5, 18.5, 32.5, 78], \n",
    "            1 - exp(-array([5, 11.5, 18.5, 32.5, 78])*sc_m[mlm]/365.25),\n",
    "            yerr = array([1 - exp(-array([5, 11.5, 18.5, 32.5, 78])*sc_m[mlm]/365.25) -\n",
    "                    percentile(simdat, 2.5, 0)/array([15.,9.,4.,4.,4.]),\n",
    "                    percentile(simdat, 97.5, 0)/array([15.,9.,4.,4.,4.]) -\n",
    "                    1 + exp(-array([5, 11.5, 18.5, 32.5, 78])*sc_m[mlm]/365.25)\n",
    "                    ]),\n",
    "                    color='b')\n",
    "# women\n",
    "simdat = zeros([n_sample, 5])\n",
    "for i in xrange(n_sample):\n",
    "    simp = 1 - exp(-array([5, 11.5, 18.5, 32.5, 137.5])*sc_m[i]/365.25)\n",
    "    simdat[i] = binom.rvs([12,28,4,8,6], simp)\n",
    "    \n",
    "women = ax2.plot(\n",
    "    [5, 11.5, 18.5, 32.5, 137.5],\n",
    "    array([2,7,1,0,3])/array([12.,28.,4.,8.,6.]), \n",
    "    '.r', label='women')\n",
    "mlf = argmax(ll_f)\n",
    "\n",
    "ax2.errorbar([5, 11.5, 18.5, 32.5, 137.5], \n",
    "            1 - exp(-array([5, 11.5, 18.5, 32.5, 137.5])*sc_f[mlf]/365.25),\n",
    "            yerr = array([1 - exp(-array([5, 11.5, 18.5, 32.5, 137.5])*sc_f[mlf]/365.25) -\n",
    "                    percentile(simdat, 2.5, 0)/array([12.,28.,4.,8.,6.]),\n",
    "                    percentile(simdat, 97.5, 0)/array([12.,28.,4.,8.,6.]) -\n",
    "                    1 + exp(-array([5, 11.5, 18.5, 32.5, 137.5])*sc_f[mlf]/365.25)\n",
    "                    ]),\n",
    "                    color='r')\n",
    "\n",
    "ax2.set_ylim([-0.1, 1.1])\n",
    "\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Rate of spontaneous clearance (days^-1)')\n",
    "ax2.set_xlabel('Time since infection known')\n",
    "ax2.set_ylabel('Proportion of infections cleared (normalised)')\n",
    "\n",
    "ax2.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the chains appear to have converged well (left). In the posterior predictive check (right), point markers show the proportion of patients returning at each time point who had cleared their infection. The solid line and error bars indicate maximum likelihood and 95% of sample predictions, and cover all data points.\n",
    "\n",
    "## Estimating national prevalence\n",
    "\n",
    "The sampled parameter values are now used to infer prevalence in men and women in different age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this script contains the functions for three-part observations (tests, symptomatic diagnoses, asymptomatic diagnoses) too\n",
    "# running this script takes a little while because of all the symbolic algebra\n",
    "%run test_diag_fun.py\n",
    "\n",
    "from numpy import *\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# men first...\n",
    "prev_m_15_19 = zeros(n_sample)\n",
    "inc_m_15_19 = zeros(n_sample)\n",
    "scr_m_15_19 = zeros(n_sample)\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_m_15_19[i], scr_m_15_19[i]] = fsolve(lambda x: test_diag_fun(concatenate([\n",
    "                    x, array([\n",
    "                            1-p_asymp_m[i], # proportion of incident infections which are symptomatic\n",
    "                            sc_m[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_m[i], \n",
    "                            p_false_pos_m[i]\n",
    "                        ])])) - array([test_rate_m_15_19[i],diag_rate_m_15_19[i]]), [0.09, 0.25])\n",
    "    prev_m_15_19[i] = dyn_fun(inc_m_15_19[i]*p_asymp_m[i], sc_m[i] + scr_m_15_19[i]*p_true_pos_m[i], inc_m_15_19[i]*(1-p_asymp_m[i]), sc_m[i] + scr_m_15_19[i]*p_true_pos_m[i] + att_symp[i]*p_true_pos_m[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_m_20_24 = zeros(n_sample)\n",
    "inc_m_20_24 = zeros(n_sample)\n",
    "scr_m_20_24 = zeros(n_sample)\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_m_20_24[i], scr_m_20_24[i]] = fsolve(lambda x: test_diag_fun(concatenate([\n",
    "                    x, array([\n",
    "                            1-p_asymp_m[i], # proportion of incident infections which are symptomatic\n",
    "                            sc_m[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_m[i], \n",
    "                            p_false_pos_m[i]\n",
    "                        ])])) - array([test_rate_m_20_24[i],diag_rate_m_20_24[i]]), [0.09, 0.25])\n",
    "    prev_m_20_24[i] = dyn_fun(inc_m_20_24[i]*p_asymp_m[i], sc_m[i] + scr_m_20_24[i]*p_true_pos_m[i], inc_m_20_24[i]*(1-p_asymp_m[i]), sc_m[i] + att_symp[i]*p_true_pos_m[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_m_15_24 = zeros(n_sample)\n",
    "inc_m_15_24 = zeros(n_sample)\n",
    "scr_m_15_24 = zeros(n_sample)\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_m_15_24[i], scr_m_15_24[i]] = fsolve(lambda x: test_diag_fun(concatenate([\n",
    "                    x, array([\n",
    "                            1-p_asymp_m[i], # proportion of incident infections which are symptomatic\n",
    "                            sc_m[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_m[i], \n",
    "                            p_false_pos_m[i]\n",
    "                        ])])) - array([test_rate_m_15_24[i],diag_rate_m_15_24[i]]), [0.09, 0.25])\n",
    "    prev_m_15_24[i] = dyn_fun(inc_m_15_24[i]*p_asymp_m[i], sc_m[i] + scr_m_15_24[i]*p_true_pos_m[i], inc_m_15_24[i]*(1-p_asymp_m[i]), sc_m[i] + scr_m_15_24[i]*p_true_pos_m[i] + att_symp[i]*p_true_pos_m[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... then women\n",
    "prev_f_15_19 = zeros(n_sample)\n",
    "inc_f_15_19 = zeros(n_sample)\n",
    "scr_f_15_19 = zeros(n_sample)\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_f_15_19[i], scr_f_15_19[i]] = fsolve(lambda x: test_diag_fun(concatenate([\n",
    "                    x, array([\n",
    "                            1-p_asymp_f[i], # proportion of incident infections which are symptomatic\n",
    "                            sc_f[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_f[i], \n",
    "                            p_false_pos_f[i]\n",
    "                        ])])) - array([test_rate_f_15_19[i],diag_rate_f_15_19[i]]), [0.03, 0.44])\n",
    "    prev_f_15_19[i] = dyn_fun(inc_f_15_19[i]*p_asymp_f[i], sc_f[i] + scr_f_15_19[i]*p_true_pos_f[i], inc_f_15_19[i]*(1-p_asymp_f[i]), sc_f[i] + scr_f_15_19[i]*p_true_pos_f[i] + att_symp[i]*p_true_pos_f[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_f_20_24 = zeros(n_sample)\n",
    "inc_f_20_24 = zeros(n_sample)\n",
    "scr_f_20_24 = zeros(n_sample)\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_f_20_24[i], scr_f_20_24[i]] = fsolve(lambda x: test_diag_fun(concatenate([\n",
    "                    x, array([\n",
    "                            1-p_asymp_f[i], # proportion of incident infections which are symptomatic\n",
    "                            sc_f[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_f[i], \n",
    "                            p_false_pos_f[i]\n",
    "                        ])])) - array([test_rate_f_20_24[i],diag_rate_f_20_24[i]]), [0.03, 0.44])\n",
    "    prev_f_20_24[i] = dyn_fun(inc_f_20_24[i]*p_asymp_f[i], sc_f[i] + scr_f_20_24[i]*p_true_pos_f[i], inc_f_20_24[i]*(1-p_asymp_f[i]), sc_f[i] + scr_f_20_24[i]*p_true_pos_f[i] + att_symp[i]*p_true_pos_f[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_f_15_24 = zeros(n_sample)\n",
    "inc_f_15_24 = zeros(n_sample)\n",
    "scr_f_15_24 = zeros(n_sample)\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_f_15_24[i], scr_f_15_24[i]] = fsolve(lambda x: test_diag_fun(concatenate([\n",
    "                    x, array([\n",
    "                            1-p_asymp_f[i], # proportion of incident infections which are symptomatic\n",
    "                            sc_f[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_f[i], \n",
    "                            p_false_pos_f[i]\n",
    "                        ])])) - array([test_rate_f_15_24[i],diag_rate_f_15_24[i]]), [0.03, 0.44])\n",
    "    prev_f_15_24[i] = dyn_fun(inc_f_15_24[i]*p_asymp_f[i], sc_f[i] + scr_f_15_24[i]*p_true_pos_f[i], inc_f_15_24[i]*(1-p_asymp_f[i]), sc_f[i] + scr_f_15_24[i]*p_true_pos_f[i] + att_symp[i]*p_true_pos_f[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "h_2012_m_15_19 = ax1.hist(prev_m_15_19, bins=20, normed=true, histtype='step', color='cyan', label='15-19 years')\n",
    "h_2012_m_20_24 = ax1.hist(prev_m_20_24, bins=20, normed=true, histtype='step', color='blue', label='20-24 years')\n",
    "ax1.errorbar(0.001, 25, xerr=[[0],[0.022-0.001]], ecolor='cyan', capsize=10)\n",
    "ax1.errorbar(0.022, 30, xerr=[[0],[0.052-0.022]], ecolor='blue', capsize=10)\n",
    "ax1.annotate('18-19 years', [0.001, 25], color='0.5')\n",
    "ax1.annotate('20-24 years', [0.022, 30], color='0.5')\n",
    "ax1.set_xlabel('Prevalence')\n",
    "ax1.set_xlim(0,0.1)\n",
    "ax1.set_ylim(0,90)\n",
    "ax1.set_title('Sexually active men')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "h_2012_f_15_19 = ax2.hist(prev_f_15_19, range=[min(prev_f_15_19),max(prev_f_15_19)], bins=20, normed=true, histtype='step', color='fuchsia', label='15-19 years')\n",
    "h_2012_f_20_24 = ax2.hist(prev_f_20_24, range=[min(prev_f_20_24),max(prev_f_20_24)], bins=20, normed=true, histtype='step', color='r', label='20-24 years')\n",
    "ax2.errorbar(0.009, 20, xerr=[[0],[0.058-0.009]], ecolor='fuchsia', capsize=10)\n",
    "ax2.errorbar(0.025, 25, xerr=[[0],[0.086-0.025]], ecolor='fuchsia', capsize=10)\n",
    "ax2.errorbar(0.017, 30, xerr=[[0],[0.042-0.017]], ecolor='r', capsize=10)\n",
    "ax2.annotate('16-17 years', [0.009, 20], color='0.5')\n",
    "ax2.annotate('18-19 years', [0.025, 25], color='0.5')\n",
    "ax2.annotate('20-24 years', [0.017, 30], color='0.5')\n",
    "ax2.set_xlabel('Prevalence')\n",
    "ax2.set_xlim(0,0.1)\n",
    "ax2.set_ylim(0,90)\n",
    "ax2.set_title('Sexually active women')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "h_2012_m_15_24 = ax1.hist(prev_m_15_24, bins=20, normed=true, color='b')\n",
    "ax1.fill_betweenx([0,100], percentile(prev_m_15_24, 2.5), percentile(prev_m_15_24, 97.5), facecolor='b', alpha=0.5)\n",
    "ax1.errorbar(0.015, 85, xerr=[[0],[0.034-0.015]], ecolor='k', capsize=10)\n",
    "ax1.set_xlabel('Prevalence')\n",
    "ax1.set_xlim(0,0.06)\n",
    "ax1.set_ylim(0,90)\n",
    "ax1.set_title('Sexually active men, 15-24 years')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "h_2012_f_15_24 = ax2.hist(prev_f_15_24, range=[min(prev_f_15_24),max(prev_f_15_24)], bins=20, normed=true, color='r')\n",
    "ax2.fill_betweenx([0,100], percentile(prev_f_15_24, 2.5), percentile(prev_f_15_24, 97.5), facecolor='r', alpha=0.5)\n",
    "ax2.errorbar(0.015, 85, xerr=[[0],[0.034-0.015]], ecolor='k', capsize=10)\n",
    "ax2.set_xlabel('Prevalence')\n",
    "ax2.set_xlim(0,0.06)\n",
    "ax2.set_ylim(0,90)\n",
    "ax2.set_title('Sexually active women, 15-24 years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symptomatic and asymptomatic diagnoses\n",
    "\n",
    "Although the data does not report the number of diagnoses that were in symptomatic and asymptomatic cases, we can propose different numbers of symptomatic and asymptomatic diagnoses and examine the inferences which would have followed in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# men first...\n",
    "prev_m = zeros(n_sample)\n",
    "inc_m = zeros(n_sample)\n",
    "scr_m = zeros(n_sample)\n",
    "p_symp_m = zeros(n_sample)\n",
    "\n",
    "# there were 48387 diagnoses in men aged 15-24\n",
    "# don't allow all symptomatic or all asymptomatic - messes with gamma distributions\n",
    "sample_symp_m = ceil(48386*random.uniform(size = n_sample))\n",
    "diag_rate_symp_m_15_24 = random.gamma(sample_symp_m, 1, size=n_sample)/pop_active_m_15_24\n",
    "\n",
    "sample_asymp_m = 48387 - sample_symp_m\n",
    "diag_rate_asymp_m_15_24 = random.gamma(sample_asymp_m, 1, size=n_sample)/pop_active_m_15_24\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_m[i], scr_m[i], p_symp_m[i]] = fsolve(lambda x: test_diag_sym_asym_fun(concatenate([\n",
    "                    x, array([\n",
    "                            sc_m[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_m[i], \n",
    "                            p_false_pos_m[i]\n",
    "                        ])])) - array([test_rate_m_15_24[i],diag_rate_symp_m_15_24[i],diag_rate_asymp_m_15_24[i]]), \n",
    "                                               [0.01, 0.3, 0.21])\n",
    "    prev_m[i] = dyn_fun(\n",
    "        inc_m[i]*(1-p_symp_m[i]), \n",
    "        sc_m[i] + scr_m[i]*p_true_pos_m[i], \n",
    "        inc_m[i]*p_symp_m[i], \n",
    "        sc_m[i] + scr_m[i]*p_true_pos_m[i] + att_symp[i]*p_true_pos_m[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ...then women\n",
    "prev_f = zeros(n_sample)\n",
    "inc_f = zeros(n_sample)\n",
    "scr_f = zeros(n_sample)\n",
    "p_symp_f = zeros(n_sample)\n",
    "\n",
    "# there were 88101 diagnoses in women aged 15-24\n",
    "# don't allow all symptomatic or all asymptomatic - messes with gamma distributions\n",
    "sample_symp_f = ceil(88100*random.uniform(size = n_sample))\n",
    "diag_rate_symp_f_15_24 = random.gamma(sample_symp_f, 1, size=n_sample)/pop_active_f_15_24\n",
    "\n",
    "sample_asymp_f = 88101 - sample_symp_f\n",
    "diag_rate_asymp_f_15_24 = random.gamma(sample_asymp_f, 1, size=n_sample)/pop_active_f_15_24\n",
    "\n",
    "for i in xrange(n_sample):\n",
    "    [inc_f[i], scr_f[i], p_symp_f[i]] = fsolve(lambda x: test_diag_sym_asym_fun(concatenate([\n",
    "                    x, array([\n",
    "                            sc_f[i], # rate of self-clear \n",
    "                            att_symp[i],\n",
    "                            p_true_pos_f[i], \n",
    "                            p_false_pos_f[i]\n",
    "                        ])])) - array([test_rate_f_15_24[i],diag_rate_symp_f_15_24[i],diag_rate_asymp_f_15_24[i]]), \n",
    "                                               [0.01, 0.3, 0.21])\n",
    "    prev_f[i] = dyn_fun(\n",
    "        inc_f[i]*(1-p_symp_f[i]), \n",
    "        sc_f[i] + scr_f[i]*p_true_pos_f[i], \n",
    "        inc_f[i]*p_symp_f[i], \n",
    "        sc_f[i] + scr_f[i]*p_true_pos_f[i] + att_symp[i]*p_true_pos_f[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,12))\n",
    "\n",
    "xtk_m = [0, 10000, 20000, 30000, 40000] # x-axis ticks for men\n",
    "xtk_f = [0, 20000, 40000, 60000, 80000] # x-axis ticks for women\n",
    "\n",
    "ax1 = fig.add_subplot(421)\n",
    "ax1.plot(100*sample_symp_m/48387, prev_m, '.', alpha = 0.1)\n",
    "ax1.fill_between([0,50000], 0.015, 0.034, facecolor='b', alpha=0.3)\n",
    "ax1.plot([60,60],[0,1],'--b')\n",
    "ax1.plot([80,80],[0,1],'--b')\n",
    "ax1.set_xlim([0,100])\n",
    "ax1.set_ylim([0,0.1])\n",
    "#ax1.set_xticks(xtk_m)\n",
    "ax1.set_ylabel('Prevalence')\n",
    "ax1.set_title('Sexually active men, 15-24 years')\n",
    "\n",
    "ax2 = fig.add_subplot(422)\n",
    "ax2.plot(100*sample_symp_f/88101, prev_f, '.r', alpha = 0.1)\n",
    "ax2.fill_between([0,100000], 0.022, 0.043, facecolor='r', alpha=0.3)\n",
    "ax2.plot([45,45],[0,1],'--r')\n",
    "ax2.plot([70,70],[0,1],'--r')\n",
    "ax2.set_xlim([0,100])\n",
    "ax2.set_ylim([0,0.1])\n",
    "#ax2.set_xticks(xtk_f)\n",
    "ax2.set_title('Sexually active women, 15-24 years')\n",
    "\n",
    "ax3 = fig.add_subplot(423)\n",
    "ax3.plot(100*sample_symp_m/48387, inc_m, '.', alpha = 0.1)\n",
    "ax3.plot([60,60],[0,1.2],'--b')\n",
    "ax3.plot([80,80],[0,1.2],'--b')\n",
    "ax3.set_xlim([0,100])\n",
    "ax3.set_ylim([0,1.2])\n",
    "#ax3.set_xticks(xtk_m)\n",
    "ax3.set_ylabel('Incidence')\n",
    "\n",
    "ax4 = fig.add_subplot(424)\n",
    "ax4.plot(100*sample_symp_f/88101, inc_f, '.r', alpha = 0.1)\n",
    "ax4.plot([45,45],[0,1.2],'--r')\n",
    "ax4.plot([70,70],[0,1.2],'--r')\n",
    "ax4.set_xlim([0,100])\n",
    "ax4.set_ylim([0,1.2])\n",
    "#ax4.set_xticks(xtk_f)\n",
    "\n",
    "ax5 = fig.add_subplot(425)\n",
    "ax5.plot(100*sample_symp_m/48387, scr_m, '.', alpha = 0.1)\n",
    "ax5.plot([60,60],[0,1],'--b')\n",
    "ax5.plot([80,80],[0,1],'--b')\n",
    "ax5.set_xlim([0,100])\n",
    "ax5.set_ylim([0,0.5])\n",
    "ax5.set_ylabel('Screening')\n",
    "#ax5.set_xticks(xtk_m)\n",
    "\n",
    "ax6 = fig.add_subplot(426)\n",
    "ax6.plot(100*sample_symp_f/88101, scr_f, '.r', alpha = 0.1)\n",
    "ax6.plot([45,45],[0,1],'--r')\n",
    "ax6.plot([70,70],[0,1],'--r')\n",
    "ax6.set_xlim([0,100])\n",
    "ax6.set_ylim([0,0.5])\n",
    "#ax6.set_xticks(xtk_f)\n",
    "\n",
    "ax7 = fig.add_subplot(427)\n",
    "ax7.plot(100*sample_symp_m/48387, p_symp_m, '.', alpha = 0.1)\n",
    "ax7.plot([60,60],[0,1],'--b')\n",
    "ax7.plot([80,80],[0,1],'--b')\n",
    "ax7.plot([0,100],[0.04,0.04],'--b')\n",
    "ax7.plot([0,100],[0.25,0.25],'--b')\n",
    "ax7.set_xlim([0,100])\n",
    "ax7.set_ylim([0,1])\n",
    "ax7.set_xlabel('Proportion of diagnoses symptomatic (%)')\n",
    "ax7.set_ylabel('Proportion of incident infections symptomatic')\n",
    "#ax7.set_xticks(xtk_m)\n",
    "\n",
    "ax8 = fig.add_subplot(428)\n",
    "ax8.plot(100*sample_symp_f/88101, p_symp_f, '.r', alpha = 0.1)\n",
    "ax8.plot([45,45],[0,1],'--r')\n",
    "ax8.plot([70,70],[0,1],'--r')\n",
    "ax8.plot([0,100],[0.06,0.06],'--r')\n",
    "ax8.plot([0,100],[0.30,0.30],'--r')\n",
    "ax8.set_xlim([0,100])\n",
    "ax8.set_ylim([0,1])\n",
    "ax8.set_xlabel('Proportion of diagnoses symptomatic (%)')\n",
    "#ax8.set_xticks(xtk_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot only the prevalence, for figure in paper\n",
    "\n",
    "fig = plt.figure(figsize = (10,3))\n",
    "\n",
    "xtk_m = [0, 10000, 20000, 30000, 40000] # x-axis ticks for men\n",
    "xtk_f = [0, 20000, 40000, 60000, 80000] # x-axis ticks for women\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(100*sample_symp_m/48387, prev_m, '.', alpha = 0.1)\n",
    "ax1.fill_between([0,50000], 0.015, 0.034, facecolor='b', alpha=0.3)\n",
    "ax1.set_xlim([0,100])\n",
    "ax1.set_ylim([0,0.1])\n",
    "ax1.set_xlabel('Proportion of diagnoses symptomatic (%)')\n",
    "ax1.set_ylabel('Prevalence')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(100*sample_symp_f/88101, prev_f, '.r', alpha = 0.1)\n",
    "ax2.fill_between([0,100000], 0.022, 0.043, facecolor='r', alpha=0.3)\n",
    "ax2.set_xlim([0,100])\n",
    "ax2.set_ylim([0,0.1])\n",
    "ax2.set_xlabel('Proportion of diagnoses symptomatic (%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
